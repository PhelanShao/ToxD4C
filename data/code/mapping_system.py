#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Chemical Bridge Table System
åŒ–å­¦å“æ¡¥è¡¨ç³»ç»Ÿ

æ„å»ºå®Œæ•´çš„ chid â†’ (casn, dsstox_substance_id) â†’ PUBCHEM_CID æ˜ å°„ç³»ç»Ÿ
å¹¶åŸºäºMC5-6æ•°æ®é‡æ–°è®¡ç®—tcplåˆ†æ•°
"""

import pandas as pd
import numpy as np
import re
from scipy import stats
from sklearn.metrics import roc_curve
import warnings
warnings.filterwarnings('ignore')

class ChemicalBridgeSystem:
    """åŒ–å­¦å“æ¡¥è¡¨ç³»ç»Ÿ"""
    
    def __init__(self):
        self.bridge_table = None
        self.cas_pubchem_mapping = None
        self.mc56_data = None
        self.chemical_scores = None
        self.pubchem_scores = None
        
    def normalize_cas(self, cas_series):
        """æ ‡å‡†åŒ–CASå·æ ¼å¼"""
        print("ğŸ”§ æ ‡å‡†åŒ–CASå·æ ¼å¼")
        
        def clean_cas(cas):
            if pd.isna(cas):
                return None
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ¸…ç†
            cas_str = str(cas).strip().upper()
            # ç§»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™æ•°å­—å’Œè¿å­—ç¬¦
            cas_clean = re.sub(r'[^\d\-]', '', cas_str)
            # ç¡®ä¿æ ¼å¼ä¸º XXXXX-XX-X
            if re.match(r'^\d{2,7}-\d{2}-\d$', cas_clean):
                return cas_clean
            return None
        
        normalized = cas_series.apply(clean_cas)
        valid_count = normalized.notna().sum()
        print(f"  CASæ ‡å‡†åŒ–: {valid_count:,}/{len(cas_series):,} æœ‰æ•ˆ")
        
        return normalized
    
    def load_sc2_data(self):
        """åŠ è½½SC1-SC2æ•°æ®æ„å»ºåŸºç¡€æ¡¥è¡¨"""
        print("\nğŸ“Š åŠ è½½SC1-SC2æ•°æ®æ„å»ºåŸºç¡€æ¡¥è¡¨")
        print("-" * 50)
        
        # åŠ è½½SC1-SC2æ•°æ®
        sc2_file = 'data_collation/Summary_Files/INVITRODB_V4_2_SUMMARY/sc1_sc2_invitrodb_v4_2_SEPT2024.xlsx'
        
        print("åŠ è½½SC1-SC2æ•°æ®...")
        sc2_data = pd.read_excel(sc2_file)
        print(f"SC2åŸå§‹æ•°æ®: {len(sc2_data):,} è®°å½•")
        
        # æå–åŒ–å­¦å“æ ‡è¯†ç¬¦
        chem_ids = sc2_data[['chid', 'casn', 'dsstox_substance_id']].drop_duplicates()
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        valid_chem_ids = chem_ids.dropna(subset=['chid'])
        print(f"æœ‰æ•ˆåŒ–å­¦å“è®°å½•: {len(valid_chem_ids):,}")
        
        # æ ‡å‡†åŒ–CASå·
        valid_chem_ids['casn_normalized'] = self.normalize_cas(valid_chem_ids['casn'])
        
        # ç»Ÿè®¡
        print(f"å”¯ä¸€chid: {valid_chem_ids['chid'].nunique():,}")
        print(f"æœ‰æ•ˆCASå·: {valid_chem_ids['casn_normalized'].notna().sum():,}")
        print(f"æœ‰æ•ˆDTXSID: {valid_chem_ids['dsstox_substance_id'].notna().sum():,}")
        
        self.bridge_table = valid_chem_ids
        return valid_chem_ids
    
    def load_cas_pubchem_mappings(self):
        """åŠ è½½å’Œåˆå¹¶æ‰€æœ‰CASâ†’PUBCHEM_CIDæ˜ å°„"""
        print("\nğŸ”— åŠ è½½å’Œåˆå¹¶CASâ†’PUBCHEM_CIDæ˜ å°„")
        print("-" * 50)
        
        mappings = []
        
        # 1. ä»tox21_toxrefdb_matched_via_cas.csvåŠ è½½
        print("1. åŠ è½½tox21_toxrefdbæ•°æ®...")
        tox21_data = pd.read_csv('tox21_toxrefdb_matched_via_cas.csv')
        
        tox21_mapping = tox21_data[['CAS_NORM', 'PUBCHEM_CID']].copy()
        tox21_mapping['casn_normalized'] = self.normalize_cas(tox21_mapping['CAS_NORM'])
        tox21_mapping = tox21_mapping.dropna(subset=['casn_normalized', 'PUBCHEM_CID'])
        tox21_mapping['source'] = 'tox21_toxrefdb'
        
        print(f"  Tox21æ˜ å°„: {len(tox21_mapping):,} è®°å½•, {tox21_mapping['PUBCHEM_CID'].nunique():,} å”¯ä¸€CID")
        mappings.append(tox21_mapping[['casn_normalized', 'PUBCHEM_CID', 'source']])
        
        # 2. å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–CASâ†’PUBCHEM_CIDæ˜ å°„æº
        # ä¾‹å¦‚ï¼šChEMBL, DrugBankç­‰æ•°æ®åº“çš„æ˜ å°„
        
        # åˆå¹¶æ‰€æœ‰æ˜ å°„
        if mappings:
            all_mappings = pd.concat(mappings, ignore_index=True)
            
            # å»é‡å¤„ç†ï¼šåŒä¸€CASå¯¹åº”å¤šä¸ªPUBCHEM_CIDæ—¶çš„å¤„ç†è§„åˆ™
            print("\nå¤„ç†CASâ†’PUBCHEM_CIDçš„å¤šå¯¹å¤šæ˜ å°„...")
            
            # ç»Ÿè®¡æ¯ä¸ªCASå¯¹åº”çš„PUBCHEM_CIDæ•°é‡
            cas_counts = all_mappings.groupby('casn_normalized')['PUBCHEM_CID'].nunique()
            multi_mapping = cas_counts[cas_counts > 1]
            
            print(f"  ä¸€å¯¹ä¸€æ˜ å°„: {(cas_counts == 1).sum():,} ä¸ªCAS")
            print(f"  ä¸€å¯¹å¤šæ˜ å°„: {len(multi_mapping):,} ä¸ªCAS")
            
            # å¯¹äºä¸€å¯¹å¤šçš„æƒ…å†µï¼Œé€‰æ‹©æœ€å°çš„PUBCHEM_CIDï¼ˆé€šå¸¸æ˜¯parent compoundï¼‰
            final_mapping = all_mappings.groupby('casn_normalized').agg({
                'PUBCHEM_CID': 'min',  # é€‰æ‹©æœ€å°çš„CID
                'source': 'first'
            }).reset_index()
            
            print(f"  æœ€ç»ˆæ˜ å°„: {len(final_mapping):,} ä¸ªCASâ†’PUBCHEM_CID")
            
            self.cas_pubchem_mapping = final_mapping
            return final_mapping
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°CASâ†’PUBCHEM_CIDæ˜ å°„æ•°æ®")
            return pd.DataFrame()
    
    def create_complete_bridge_table(self):
        """åˆ›å»ºå®Œæ•´çš„æ¡¥è¡¨"""
        print("\nğŸŒ‰ åˆ›å»ºå®Œæ•´çš„chidâ†’PUBCHEM_CIDæ¡¥è¡¨")
        print("-" * 50)
        
        if self.bridge_table is None or self.cas_pubchem_mapping is None:
            print("âŒ ç¼ºå°‘åŸºç¡€æ•°æ®")
            return None
        
        # é€šè¿‡CASå·è¿æ¥
        bridge_with_pubchem = self.bridge_table.merge(
            self.cas_pubchem_mapping[['casn_normalized', 'PUBCHEM_CID']], 
            on='casn_normalized', 
            how='left'
        )
        
        # ç»Ÿè®¡æ˜ å°„ç»“æœ
        total_chids = len(bridge_with_pubchem)
        mapped_chids = bridge_with_pubchem['PUBCHEM_CID'].notna().sum()
        
        print(f"æ¡¥è¡¨ç»Ÿè®¡:")
        print(f"  æ€»chidæ•°: {total_chids:,}")
        print(f"  æ˜ å°„åˆ°PUBCHEM_CID: {mapped_chids:,} ({mapped_chids/total_chids*100:.1f}%)")
        print(f"  å”¯ä¸€PUBCHEM_CID: {bridge_with_pubchem['PUBCHEM_CID'].nunique():,}")
        
        # ä¿å­˜æ¡¥è¡¨
        bridge_with_pubchem.to_csv('output/data/chemical_bridge_table.csv', index=False)
        print(f"âœ… æ¡¥è¡¨å·²ä¿å­˜: output/data/chemical_bridge_table.csv")
        
        self.bridge_table = bridge_with_pubchem
        return bridge_with_pubchem
    
    def load_mc56_data(self):
        """åŠ è½½MC5-6æ•°æ®"""
        print("\nğŸ“Š åŠ è½½MC5-6æ•°æ®")
        print("-" * 50)
        
        mc56_file = 'data_collation/Summary_Files/INVITRODB_V4_2_SUMMARY/mc5-6_winning_model_fits-flags_invitrodbv4_2_SEPT2024.csv'
        
        # åˆ†å—åŠ è½½ä»¥èŠ‚çœå†…å­˜
        print("åˆ†å—åŠ è½½MC5-6æ•°æ®...")
        chunks = []
        chunk_size = 50000
        
        for chunk in pd.read_csv(mc56_file, chunksize=chunk_size):
            # åªä¿ç•™å¿…è¦çš„åˆ—
            essential_cols = ['chid', 'aeid', 'hitc', 'mc6_flags', 'aenm']
            chunk_filtered = chunk[essential_cols].copy()
            
            # è¿‡æ»¤æœ‰æ•ˆçš„hitcå€¼
            valid_hitc = chunk_filtered['hitc'].isin([-1, 0, 1])
            chunk_filtered = chunk_filtered[valid_hitc]
            
            chunks.append(chunk_filtered)
        
        self.mc56_data = pd.concat(chunks, ignore_index=True)
        
        print(f"MC5-6æ•°æ®: {len(self.mc56_data):,} è®°å½•")
        print(f"å”¯ä¸€chid: {self.mc56_data['chid'].nunique():,}")
        print(f"å”¯ä¸€aeid: {self.mc56_data['aeid'].nunique():,}")
        
        # hitcåˆ†å¸ƒ
        hitc_dist = self.mc56_data['hitc'].value_counts().sort_index()
        print(f"hitcåˆ†å¸ƒ: {dict(hitc_dist)}")
        
        return self.mc56_data
    
    def calculate_chemical_scores(self):
        """è®¡ç®—åŒ–å­¦å“çº§åˆ«çš„tcplåˆ†æ•°"""
        print("\nğŸ§® è®¡ç®—åŒ–å­¦å“çº§åˆ«çš„tcplåˆ†æ•°")
        print("-" * 50)
        
        if self.mc56_data is None:
            print("âŒ ç¼ºå°‘MC5-6æ•°æ®")
            return None
        
        # ä¸¥æ ¼çš„æ•°æ®æ¸…ç†
        print("åº”ç”¨ä¸¥æ ¼çš„æ•°æ®æ¸…ç†è§„åˆ™...")
        
        # 1. ç§»é™¤hitc = -1çš„è®°å½•ï¼ˆä¸ç¡®å®šçš„ç»“æœï¼‰
        clean_data = self.mc56_data[self.mc56_data['hitc'] != -1].copy()
        print(f"  ç§»é™¤hitc=-1: {len(clean_data):,} è®°å½•ä¿ç•™")
        
        # 2. ç§»é™¤æœ‰mc6_flagsçš„è®°å½•ï¼ˆè´¨é‡æ ‡è®°ï¼‰
        if 'mc6_flags' in clean_data.columns:
            flagged = clean_data['mc6_flags'].notna() & (clean_data['mc6_flags'] != '')
            clean_data = clean_data[~flagged]
            print(f"  ç§»é™¤mc6_flags: {len(clean_data):,} è®°å½•ä¿ç•™")
        
        # 3. ç§»é™¤cytotoxç›¸å…³çš„ç«¯ç‚¹ï¼ˆå¯é€‰ï¼Œå¦‚æœéœ€è¦æ›´ä¸¥æ ¼ï¼‰
        cytotox_keywords = ['cytotox', 'viability', 'cell_death']
        if 'aenm' in clean_data.columns:
            cytotox_mask = clean_data['aenm'].str.lower().str.contains('|'.join(cytotox_keywords), na=False)
            clean_data = clean_data[~cytotox_mask]
            print(f"  ç§»é™¤cytotoxç«¯ç‚¹: {len(clean_data):,} è®°å½•ä¿ç•™")
        
        # æŒ‰chidèšåˆè®¡ç®—åˆ†æ•°
        print("æŒ‰chidèšåˆè®¡ç®—åˆ†æ•°...")
        
        chem_stats = clean_data.groupby('chid').agg({
            'hitc': ['count', 'sum'],  # count=æ€»æµ‹è¯•æ•°, sum=å‘½ä¸­æ•°
            'aeid': 'nunique'  # æµ‹è¯•çš„ç«¯ç‚¹æ•°
        }).reset_index()
        
        # å±•å¹³åˆ—å
        chem_stats.columns = ['chid', 'total_tested', 'total_hits', 'unique_endpoints']
        
        # è®¡ç®—åŸºç¡€åˆ†æ•°
        chem_stats['S_chid_basic'] = chem_stats['total_hits'] / chem_stats['total_tested']
        
        # Beta-Binomialæ”¶ç¼©ï¼ˆæ›´ç¨³å¥çš„ä¼°è®¡ï¼‰
        alpha, beta = 0.5, 0.5
        chem_stats['S_chid_robust'] = (
            (chem_stats['total_hits'] + alpha) / 
            (chem_stats['total_tested'] + alpha + beta)
        )
        
        # ä½¿ç”¨ç¨³å¥ä¼°è®¡ä½œä¸ºæœ€ç»ˆåˆ†æ•°
        chem_stats['S_chid'] = chem_stats['S_chid_robust']
        
        print(f"åŒ–å­¦å“çº§åˆ†æ•°è®¡ç®—å®Œæˆ:")
        print(f"  åŒ–å­¦å“æ•°: {len(chem_stats):,}")
        print(f"  åˆ†æ•°èŒƒå›´: {chem_stats['S_chid'].min():.6f} - {chem_stats['S_chid'].max():.6f}")
        print(f"  å¹³å‡æµ‹è¯•æ•°: {chem_stats['total_tested'].mean():.1f}")
        print(f"  å¹³å‡ç«¯ç‚¹æ•°: {chem_stats['unique_endpoints'].mean():.1f}")
        
        self.chemical_scores = chem_stats
        return chem_stats
    
    def aggregate_to_pubchem(self):
        """èšåˆåˆ°PUBCHEM_CIDçº§åˆ«"""
        print("\nğŸ”„ èšåˆåˆ°PUBCHEM_CIDçº§åˆ«")
        print("-" * 50)
        
        if self.chemical_scores is None or self.bridge_table is None:
            print("âŒ ç¼ºå°‘å¿…è¦æ•°æ®")
            return None
        
        # è¿æ¥åŒ–å­¦å“åˆ†æ•°å’Œæ¡¥è¡¨
        chem_with_pubchem = self.chemical_scores.merge(
            self.bridge_table[['chid', 'PUBCHEM_CID']], 
            on='chid', 
            how='inner'
        )
        
        print(f"è¿æ¥ç»“æœ: {len(chem_with_pubchem):,} ä¸ªchidæœ‰PUBCHEM_CID")
        
        # æŒ‰PUBCHEM_CIDèšåˆï¼ˆåŠ æƒå¹³å‡ï¼ŒæŒ‰æµ‹è¯•æ•°åŠ æƒï¼‰
        pubchem_stats = chem_with_pubchem.groupby('PUBCHEM_CID').apply(
            lambda group: pd.Series({
                'total_hits': group['total_hits'].sum(),
                'total_tested': group['total_tested'].sum(),
                'unique_endpoints': group['unique_endpoints'].sum(),
                'num_chids': len(group),
                'S_cid': group['total_hits'].sum() / group['total_tested'].sum() if group['total_tested'].sum() > 0 else 0
            })
        ).reset_index()
        
        # Beta-Binomialæ”¶ç¼©
        alpha, beta = 0.5, 0.5
        pubchem_stats['S_cid_robust'] = (
            (pubchem_stats['total_hits'] + alpha) / 
            (pubchem_stats['total_tested'] + alpha + beta)
        )
        
        # ä½¿ç”¨ç¨³å¥ä¼°è®¡
        pubchem_stats['S_global_real_tcpl'] = pubchem_stats['S_cid_robust']
        
        print(f"PUBCHEM_CIDçº§åˆ†æ•°:")
        print(f"  PUBCHEM_CIDæ•°: {len(pubchem_stats):,}")
        print(f"  åˆ†æ•°èŒƒå›´: {pubchem_stats['S_global_real_tcpl'].min():.6f} - {pubchem_stats['S_global_real_tcpl'].max():.6f}")
        print(f"  å¹³å‡æµ‹è¯•æ•°: {pubchem_stats['total_tested'].mean():.1f}")
        print(f"  å¹³å‡chidæ•°: {pubchem_stats['num_chids'].mean():.1f}")
        
        self.pubchem_scores = pubchem_stats
        return pubchem_stats

    def anchor_thresholds_with_toxrefdb(self):
        """ä½¿ç”¨ToxRefDB PODæ•°æ®é”šå®šé˜ˆå€¼"""
        print("\nâš“ ä½¿ç”¨ToxRefDB PODæ•°æ®é”šå®šé˜ˆå€¼")
        print("-" * 50)

        if self.pubchem_scores is None:
            print("âŒ ç¼ºå°‘PUBCHEM_CIDåˆ†æ•°")
            return None

        # åŠ è½½ToxRefDBæ•°æ®
        try:
            tox21_data = pd.read_csv('tox21_toxrefdb_matched_via_cas.csv')

            # è¿æ¥PODæ•°æ®
            scores_with_pod = self.pubchem_scores.merge(
                tox21_data[['PUBCHEM_CID', 'POD_MGKGDAY']].drop_duplicates(),
                on='PUBCHEM_CID',
                how='left'
            )

            # åªä½¿ç”¨æœ‰PODæ•°æ®çš„è®°å½•è¿›è¡Œé˜ˆå€¼ä¼˜åŒ–
            pod_data = scores_with_pod.dropna(subset=['POD_MGKGDAY'])

            if len(pod_data) == 0:
                print("âŒ æ²¡æœ‰PODæ•°æ®ï¼Œä½¿ç”¨åˆ†ä½æ•°é˜ˆå€¼")
                return self.use_quantile_thresholds()

            print(f"æœ‰PODæ•°æ®çš„åŒ–å­¦å“: {len(pod_data):,}")

            # è®¡ç®—ä¸åŒPODé˜ˆå€¼çš„Youden JæŒ‡æ•°
            thresholds = {}

            # äºŒåˆ†ç±»ï¼šPOD â‰¤ 10 mg/kg/day
            y_binary = (pod_data['POD_MGKGDAY'] <= 10).astype(int)
            if len(np.unique(y_binary)) > 1:
                fpr, tpr, thresh = roc_curve(y_binary, pod_data['S_global_real_tcpl'])
                youden_j = tpr - fpr
                best_idx = np.argmax(youden_j)
                thresholds['binary'] = thresh[best_idx]
                print(f"äºŒåˆ†ç±»é˜ˆå€¼ (PODâ‰¤10): {thresholds['binary']:.6f}")
            else:
                thresholds['binary'] = 0.1  # é»˜è®¤å€¼
                print("äºŒåˆ†ç±»é˜ˆå€¼: ä½¿ç”¨é»˜è®¤å€¼ 0.1")

            # ä¸‰åˆ†ç±»ï¼šPOD â‰¤ 3 å’Œ â‰¤ 30
            y_low = (pod_data['POD_MGKGDAY'] <= 3).astype(int)
            y_high = (pod_data['POD_MGKGDAY'] <= 30).astype(int)

            if len(np.unique(y_low)) > 1:
                fpr, tpr, thresh = roc_curve(y_low, pod_data['S_global_real_tcpl'])
                youden_j = tpr - fpr
                best_idx = np.argmax(youden_j)
                thresholds['ternary_high'] = thresh[best_idx]
                print(f"ä¸‰åˆ†ç±»é«˜é˜ˆå€¼ (PODâ‰¤3): {thresholds['ternary_high']:.6f}")
            else:
                thresholds['ternary_high'] = pod_data['S_global_real_tcpl'].quantile(0.67)
                print(f"ä¸‰åˆ†ç±»é«˜é˜ˆå€¼: ä½¿ç”¨P67 {thresholds['ternary_high']:.6f}")

            if len(np.unique(y_high)) > 1:
                fpr, tpr, thresh = roc_curve(y_high, pod_data['S_global_real_tcpl'])
                youden_j = tpr - fpr
                best_idx = np.argmax(youden_j)
                thresholds['ternary_low'] = thresh[best_idx]
                print(f"ä¸‰åˆ†ç±»ä½é˜ˆå€¼ (PODâ‰¤30): {thresholds['ternary_low']:.6f}")
            else:
                thresholds['ternary_low'] = pod_data['S_global_real_tcpl'].quantile(0.33)
                print(f"ä¸‰åˆ†ç±»ä½é˜ˆå€¼: ä½¿ç”¨P33 {thresholds['ternary_low']:.6f}")

            return thresholds

        except Exception as e:
            print(f"âŒ ToxRefDBé˜ˆå€¼é”šå®šå¤±è´¥: {str(e)}")
            return self.use_quantile_thresholds()

    def use_quantile_thresholds(self):
        """ä½¿ç”¨åˆ†ä½æ•°é˜ˆå€¼ä½œä¸ºä¿åº•æ–¹æ¡ˆ"""
        print("\nğŸ“Š ä½¿ç”¨åˆ†ä½æ•°é˜ˆå€¼")
        print("-" * 50)

        if self.pubchem_scores is None:
            print("âŒ ç¼ºå°‘åˆ†æ•°æ•°æ®")
            return None

        scores = self.pubchem_scores['S_global_real_tcpl']

        thresholds = {
            'binary': scores.quantile(0.75),  # P75ä½œä¸ºäºŒåˆ†ç±»é˜ˆå€¼
            'ternary_low': scores.quantile(0.33),  # P33ä½œä¸ºä¸‰åˆ†ç±»ä½é˜ˆå€¼
            'ternary_high': scores.quantile(0.67)  # P67ä½œä¸ºä¸‰åˆ†ç±»é«˜é˜ˆå€¼
        }

        print(f"åˆ†ä½æ•°é˜ˆå€¼:")
        print(f"  äºŒåˆ†ç±» (P75): {thresholds['binary']:.6f}")
        print(f"  ä¸‰åˆ†ç±»ä½ (P33): {thresholds['ternary_low']:.6f}")
        print(f"  ä¸‰åˆ†ç±»é«˜ (P67): {thresholds['ternary_high']:.6f}")

        return thresholds

    def create_classification_labels(self, thresholds):
        """åˆ›å»ºåˆ†ç±»æ ‡ç­¾"""
        print("\nğŸ·ï¸ åˆ›å»ºåˆ†ç±»æ ‡ç­¾")
        print("-" * 50)

        if self.pubchem_scores is None or thresholds is None:
            print("âŒ ç¼ºå°‘å¿…è¦æ•°æ®")
            return None

        scores_with_labels = self.pubchem_scores.copy()

        # äºŒåˆ†ç±»æ ‡ç­¾
        scores_with_labels['tcpl_binary'] = (
            scores_with_labels['S_global_real_tcpl'] >= thresholds['binary']
        ).astype(int)

        # ä¸‰åˆ†ç±»æ ‡ç­¾
        scores_with_labels['tcpl_ternary'] = 0  # é»˜è®¤ä½æ¯’æ€§
        scores_with_labels.loc[
            scores_with_labels['S_global_real_tcpl'] >= thresholds['ternary_low'],
            'tcpl_ternary'
        ] = 1  # ä¸­ç­‰æ¯’æ€§
        scores_with_labels.loc[
            scores_with_labels['S_global_real_tcpl'] >= thresholds['ternary_high'],
            'tcpl_ternary'
        ] = 2  # é«˜æ¯’æ€§

        # ç»Ÿè®¡åˆ†å¸ƒ
        binary_dist = scores_with_labels['tcpl_binary'].value_counts().sort_index()
        ternary_dist = scores_with_labels['tcpl_ternary'].value_counts().sort_index()

        print(f"åˆ†ç±»æ ‡ç­¾åˆ†å¸ƒ:")
        print(f"  äºŒåˆ†ç±» - ä½æ¯’æ€§: {binary_dist.get(0, 0):,}, é«˜æ¯’æ€§: {binary_dist.get(1, 0):,}")
        print(f"  ä¸‰åˆ†ç±» - ä½æ¯’æ€§: {ternary_dist.get(0, 0):,}, ä¸­ç­‰: {ternary_dist.get(1, 0):,}, é«˜æ¯’æ€§: {ternary_dist.get(2, 0):,}")

        # ä¿å­˜é˜ˆå€¼ä¿¡æ¯
        scores_with_labels['threshold_binary'] = thresholds['binary']
        scores_with_labels['threshold_ternary_low'] = thresholds['ternary_low']
        scores_with_labels['threshold_ternary_high'] = thresholds['ternary_high']

        self.pubchem_scores = scores_with_labels
        return scores_with_labels

    def add_labels_to_original_dataset(self, original_file='output/data/processed_final8k213.csv'):
        """å°†tcplæ ‡ç­¾æ·»åŠ åˆ°åŸå§‹æ•°æ®é›†"""
        print("\nğŸ“ å°†tcplæ ‡ç­¾æ·»åŠ åˆ°åŸå§‹æ•°æ®é›†")
        print("-" * 50)

        if self.pubchem_scores is None:
            print("âŒ ç¼ºå°‘PUBCHEM_CIDåˆ†æ•°")
            return None

        # åŠ è½½åŸå§‹æ•°æ®é›†
        original_data = pd.read_csv(original_file)
        print(f"åŸå§‹æ•°æ®é›†: {len(original_data):,} è®°å½•")

        # å‡†å¤‡è¦æ·»åŠ çš„æ ‡ç­¾
        labels_to_add = self.pubchem_scores[[
            'PUBCHEM_CID', 'S_global_real_tcpl', 'tcpl_binary', 'tcpl_ternary',
            'total_hits', 'total_tested', 'unique_endpoints', 'num_chids'
        ]].copy()

        # å·¦è¿æ¥
        enhanced_data = original_data.merge(labels_to_add, on='PUBCHEM_CID', how='left')

        # å¡«å……ç¼ºå¤±å€¼
        enhanced_data['S_global_real_tcpl'].fillna(-1, inplace=True)
        enhanced_data['tcpl_binary'].fillna(-1, inplace=True)
        enhanced_data['tcpl_ternary'].fillna(-1, inplace=True)
        enhanced_data['total_hits'].fillna(0, inplace=True)
        enhanced_data['total_tested'].fillna(0, inplace=True)
        enhanced_data['unique_endpoints'].fillna(0, inplace=True)
        enhanced_data['num_chids'].fillna(0, inplace=True)

        # è½¬æ¢æ•°æ®ç±»å‹
        enhanced_data['tcpl_binary'] = enhanced_data['tcpl_binary'].astype(int)
        enhanced_data['tcpl_ternary'] = enhanced_data['tcpl_ternary'].astype(int)
        enhanced_data['total_hits'] = enhanced_data['total_hits'].astype(int)
        enhanced_data['total_tested'] = enhanced_data['total_tested'].astype(int)
        enhanced_data['unique_endpoints'] = enhanced_data['unique_endpoints'].astype(int)
        enhanced_data['num_chids'] = enhanced_data['num_chids'].astype(int)

        # ç»Ÿè®¡ç»“æœ
        total = len(enhanced_data)
        mapped = (enhanced_data['tcpl_binary'] != -1).sum()

        print(f"æ ‡ç­¾æ·»åŠ ç»“æœ:")
        print(f"  æ€»è®°å½•æ•°: {total:,}")
        print(f"  æˆåŠŸæ˜ å°„: {mapped:,} ({mapped/total*100:.2f}%)")
        print(f"  æœªæ˜ å°„: {total-mapped:,} ({(total-mapped)/total*100:.2f}%)")

        return enhanced_data

    def run_complete_system(self):
        """è¿è¡Œå®Œæ•´çš„æ¡¥è¡¨ç³»ç»Ÿ"""
        print("ğŸš€ è¿è¡Œå®Œæ•´çš„åŒ–å­¦å“æ¡¥è¡¨ç³»ç»Ÿ")
        print("=" * 60)

        # 1. æ„å»ºåŸºç¡€æ¡¥è¡¨
        self.load_sc2_data()

        # 2. åŠ è½½CASâ†’PUBCHEM_CIDæ˜ å°„
        self.load_cas_pubchem_mappings()

        # 3. åˆ›å»ºå®Œæ•´æ¡¥è¡¨
        self.create_complete_bridge_table()

        # 4. åŠ è½½MC5-6æ•°æ®
        self.load_mc56_data()

        # 5. è®¡ç®—åŒ–å­¦å“çº§åˆ†æ•°
        self.calculate_chemical_scores()

        # 6. èšåˆåˆ°PUBCHEM_CIDçº§åˆ«
        self.aggregate_to_pubchem()

        # 7. é”šå®šé˜ˆå€¼
        thresholds = self.anchor_thresholds_with_toxrefdb()

        # 8. åˆ›å»ºåˆ†ç±»æ ‡ç­¾
        self.create_classification_labels(thresholds)

        # 9. æ·»åŠ åˆ°åŸå§‹æ•°æ®é›†
        enhanced_data = self.add_labels_to_original_dataset()

        # 10. ä¿å­˜ç»“æœ
        if enhanced_data is not None:
            output_file = 'output/data/processed_final8k213_bridge_system_labels.csv'
            enhanced_data.to_csv(output_file, index=False)
            print(f"\nğŸ’¾ æœ€ç»ˆç»“æœå·²ä¿å­˜: {output_file}")

            # ä¿å­˜PUBCHEM_CIDçº§åˆ†æ•°
            pubchem_file = 'output/data/pubchem_tcpl_scores_bridge_system.csv'
            self.pubchem_scores.to_csv(pubchem_file, index=False)
            print(f"PUBCHEM_CIDåˆ†æ•°å·²ä¿å­˜: {pubchem_file}")

        print("\nğŸ‰ åŒ–å­¦å“æ¡¥è¡¨ç³»ç»Ÿè¿è¡Œå®Œæˆ!")
        return enhanced_data

def main():
    """ä¸»å‡½æ•°"""
    bridge_system = ChemicalBridgeSystem()
    result = bridge_system.run_complete_system()
    return result

if __name__ == "__main__":
    result = main()
